import pandas as pd
import os
import re
from typing import Dict, List

class MetadataGenerator:
    def __init__(self):
        self.keywords_patterns = {
            'calendario': ['calendario', 'fechas', 'cronograma', 'acad√©mico', 'a√±o'],
            'reglamento': ['reglamento', 'normativa', 'normas', 'procedimiento'],
            'admision': ['admisi√≥n', 'ingreso', 'postulaci√≥n', 'matr√≠cula'],
            'titulacion': ['titulaci√≥n', 'egreso', 'graduaci√≥n', 'examen de t√≠tulo'],
            'academico': ['acad√©mico', 'estudios', 'asignatura', 'ramo', 'carrera'],
            'financiero': ['financiero', 'arancel', 'pago', 'obligaci√≥n econ√≥mica'],
            'convivencia': ['convivencia', 'conducta', 'disciplina', '√©tica']
        }
    
    def extract_title_from_filename(self, filename: str) -> str:
        """Extrae un t√≠tulo legible del nombre del archivo"""
        # Remover extensi√≥n
        name = os.path.splitext(filename)[0]
        
        # Remover caracteres especiales y n√∫meros al inicio
        name = re.sub(r'^\d+-', '', name)  # Remover prefijos num√©ricos
        name = re.sub(r'[-_]', ' ', name)  # Reemplazar guiones y underscores con espacios
        
        # Capitalizar palabras
        words = name.split()
        capitalized_words = [word.capitalize() for word in words]
        
        return ' '.join(capitalized_words)
    
    def generate_description(self, filename: str, title: str) -> str:
        """Genera una descripci√≥n autom√°tica basada en palabras clave del archivo"""
        filename_lower = filename.lower()
        title_lower = title.lower()
        
        description_parts = []
        
        # Detectar tipo de documento
        if any(keyword in filename_lower or keyword in title_lower 
               for keyword in self.keywords_patterns['calendario']):
            description_parts.append("Calendario oficial con fechas importantes")
        
        if any(keyword in filename_lower or keyword in title_lower 
               for keyword in self.keywords_patterns['reglamento']):
            description_parts.append("Documento normativo institucional")
        
        if any(keyword in filename_lower or keyword in title_lower 
               for keyword in self.keywords_patterns['admision']):
            description_parts.append("Procesos de admisi√≥n y matr√≠cula")
        
        if any(keyword in filename_lower or keyword in title_lower 
               for keyword in self.keywords_patterns['titulacion']):
            description_parts.append("Procedimientos de titulaci√≥n y egreso")
        
        if any(keyword in filename_lower or keyword in title_lower 
               for keyword in self.keywords_patterns['academico']):
            description_parts.append("Aspectos acad√©micos y de estudios")
        
        # A√±adir a√±o si se detecta
        year_match = re.search(r'20\d{2}', filename)
        if year_match:
            description_parts.append(f"vigente a√±o {year_match.group()}")
        
        return '. '.join(description_parts) + '.' if description_parts else "Documento institucional de la universidad."

def procesar_csv_automatico(archivo_csv: str, archivo_salida: str = None):
    """
    Procesa autom√°ticamente un CSV de documentos y genera metadatos inteligentes
    
    Args:
        archivo_csv (str): Ruta al archivo CSV original
        archivo_salida (str): Ruta para guardar el CSV corregido (opcional)
    """
    
    if archivo_salida is None:
        archivo_salida = archivo_csv.replace('.csv', '_corregido.csv')
    
    # Leer el CSV original
    df = pd.read_csv(archivo_csv)
    
    # Inicializar generador de metadatos
    metadata_gen = MetadataGenerator()
    
    # Procesar cada fila
    nuevas_filas = []
    
    for _, fila in df.iterrows():
        doc_id = fila['doc_id']
        
        # Generar metadatos autom√°ticamente
        title = metadata_gen.extract_title_from_filename(doc_id)
        description = metadata_gen.generate_description(doc_id, title)
        
        nueva_fila = {
            'doc_id': doc_id,
            'title': title,
            'filename': doc_id,  # Usar el doc_id como filename por defecto
            'description': description
        }
        
        nuevas_filas.append(nueva_fila)
    
    # Crear nuevo DataFrame
    df_corregido = pd.DataFrame(nuevas_filas)
    
    # Guardar el CSV corregido
    df_corregido.to_csv(archivo_salida, index=False)
    print(f"‚úÖ CSV corregido guardado como: {archivo_salida}")
    print(f"üìä Total de documentos procesados: {len(df_corregido)}")
    
    return df_corregido

# Script de uso r√°pido
if __name__ == "__main__":
    # Ejemplo de uso
    archivo_original = "tu_archivo.csv"  # Cambia por la ruta real
    
    try:
        df_resultado = procesar_csv_automatico(archivo_original)
        
        # Mostrar preview de los resultados
        print("\nüìã Preview de los metadatos generados:")
        print(df_resultado[['doc_id', 'title', 'description']].head())
        
    except FileNotFoundError:
        print(f"‚ùå Error: No se encontr√≥ el archivo {archivo_original}")
    except Exception as e:
        print(f"‚ùå Error al procesar el CSV: {e}")